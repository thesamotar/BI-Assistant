# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Self-Updating AI Assistant for Business Intelligence ‚Äî a RAG + RLHF system that fetches live news about GenAI competitors via EventRegistry, indexes article chunks as vector embeddings in Supabase (pgvector), and answers queries via Gemini with citation-based responses. User feedback drives UCB1 bandit re-ranking of future results.

## Running the Project

**FastAPI backend:**
```bash
python -m uvicorn backend.main:app --reload --host 127.0.0.1 --port 8000
```

**Streamlit frontend:**
```bash
python -m streamlit run frontend/streamlit_app.py
```

**Data pipeline (fetch ‚Üí translate ‚Üí chunk ‚Üí embed ‚Üí index):**
```bash
python -m workflows.langgraph_pipeline
```

**n8n workflow orchestrator (Docker):**
```bash
docker-compose up
# Access at http://localhost:5678  (credentials: admin / admin123)
```

**PPO experiment (optional, educational):**
```bash
python -m rl.ppo_experiment
```

## Architecture

### Backend (`backend/`)
The real implementation lives in `backend/`, not in the root `app.py` (which is legacy and lives in `_old/`).

- `backend/main.py` ‚Äî FastAPI entry point; warms up embeddings and Supabase on startup
- `backend/config.py` ‚Äî Pydantic `BaseSettings`; all secrets come from `.env`, never hardcoded
- `backend/routers/ask.py` ‚Äî `POST /ask`: embeds query ‚Üí `match_documents` RPC (top 2√ók) ‚Üí UCB1 re-rank ‚Üí Gemini answer
- `backend/routers/feedback.py` ‚Äî `POST /feedback`: stores thumbs up/down in Supabase, updates bandit
- `backend/routers/health.py` ‚Äî `GET /health`: Supabase connectivity check
- `backend/services/embeddings.py` ‚Äî `get_embeddings()` (HuggingFace `all-MiniLM-L6-v2`, 384d, lru_cache)
- `backend/services/feedback_rl.py` ‚Äî Supabase client, UCB1 bandit singleton, `store_feedback()`, `get_feedback_scores()`
- `backend/services/rag_pipeline.py` ‚Äî `FeedbackAwareRetriever` (LangChain `BaseRetriever`) + LCEL chain + `run_rag_pipeline()`

### Data Pipeline (`workflows/langgraph_pipeline.py`)
6-node LangGraph graph, run with `python -m workflows.langgraph_pipeline`:

```
fetch_articles ‚Üí load_articles ‚Üí translate_non_english ‚Üí chunk_documents ‚Üí generate_embeddings ‚Üí index_to_supabase
```

- `fetch_articles` ‚Äî queries EventRegistry for 8 companies, last 30 days, 50 articles each; saves to `genai_competitors_articles.json`
- `translate_non_english` ‚Äî detects language; translates non-English via Gemini
- `chunk_documents` ‚Äî 3200-char chunks, 400-char overlap; SHA-256 `doc_id` per `url_chunkindex`
- `generate_embeddings` ‚Äî batch=64, 384-dim embeddings
- `index_to_supabase` ‚Äî upsert on `doc_id` (idempotent)

### Reinforcement Learning (`rl/`)
- `rl/bandit.py` ‚Äî `UCB1Bandit`: `update()`, `get_score()`, `load_from_supabase()`, `save_to_json()`
- `rl/ppo_experiment.py` ‚Äî PPO re-ranker (research/educational, not used in production)

### Frontend (`frontend/streamlit_app.py`)
Fully implemented Streamlit dashboard: query input, answer display, source scores table, üëçüëé feedback buttons, query history, health indicator in sidebar.

## Key Configuration

All credentials are in `.env` (gitignored). Copy `.env.example` to `.env` and fill in:

| Variable | Purpose |
|----------|---------|
| `SUPABASE_URL` | Supabase project URL |
| `SUPABASE_KEY` | Supabase service role key |
| `SUPABASE_DB_PASSWORD` | Database password |
| `GEMINI_API_KEY` | Google Gemini API key |
| `EVENT_REGISTRY_API_KEY` | EventRegistry (newsapi.ai) key |
| `GEMINI_MODEL` | Default: `gemini-2.5-flash` |
| `EMBEDDING_MODEL` | Default: `sentence-transformers/all-MiniLM-L6-v2` |
| `NEWS_LOOKBACK_DAYS` | Default: `30` |
| `NEWS_MAX_ITEMS_PER_COMPANY` | Default: `50` |

**Never hardcode credentials** ‚Äî `backend/config.py` uses empty string defaults and reads everything from `.env`.

## Requirements

```bash
pip install -r requirements.txt
```

Key packages: `fastapi`, `uvicorn`, `pydantic-settings`, `langchain`, `langchain-google-genai`, `langchain-huggingface`, `langgraph`, `sentence-transformers`, `supabase`, `google-generativeai`, `eventregistry`, `langdetect`, `streamlit`.

## Tech Stack

| Layer | Technology |
|-------|-----------|
| Backend | FastAPI + Pydantic Settings |
| LLM | Google Gemini 2.5-flash (via LangChain) |
| Embeddings | `sentence-transformers/all-MiniLM-L6-v2` (384d) |
| Vector store | Supabase pgvector (`match_documents` RPC) |
| RAG framework | LangChain LCEL |
| Data pipeline | LangGraph (6-node graph) |
| News source | EventRegistry (newsapi.ai) |
| Re-ranking | UCB1 multi-armed bandit (`rl/bandit.py`) |
| Frontend | Streamlit |
| Orchestration | n8n (Docker) |

## File Structure Notes

- `_old/` ‚Äî legacy monolithic code (Elasticsearch-based `app.py`, old 3-script pipeline, test scripts); gitignored
- `genai_competitors_articles.json` ‚Äî pipeline output; gitignored (regenerated by `fetch_articles` node)
- `backend/config.py` ‚Äî safe to commit; no hardcoded secrets
- `.env` ‚Äî gitignored; contains real credentials
