# BI Assistant

> A self-updating AI for Business Intelligence â€” RAG + RLHF powered by LangChain, Gemini, and Supabase.

[![CI](https://github.com/thesamotar/BI-Assistant/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/thesamotar/BI-Assistant/actions/workflows/ci-cd.yml)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green)
![LangChain](https://img.shields.io/badge/LangChain-LCEL-orange)
![Supabase](https://img.shields.io/badge/Supabase-pgvector-3ECF8E)

BI Assistant fetches live news about GenAI competitors (OpenAI, Anthropic, Google DeepMind, and more), indexes them as vector embeddings in Supabase, and answers natural-language queries via Gemini with cited sources. Every ğŸ‘/ğŸ‘ you give re-ranks future results through a UCB1 multi-armed bandit â€” the assistant gets smarter the more you use it.

---

## Features

- **Live data ingestion** â€” one command fetches, translates, chunks, embeds, and indexes ~400 articles from EventRegistry
- **Citation-based answers** â€” Gemini answers are grounded in retrieved sources, with URLs cited inline
- **Feedback-driven re-ranking** â€” UCB1 bandit adjusts document scores based on user votes, persisted in Supabase
- **Streamlit dashboard** â€” query input, source score table, ğŸ‘ğŸ‘ buttons, query history, live health indicators
- **Fully modular backend** â€” FastAPI + LangChain LCEL, clean separation of routers/services/models
- **CI** â€” ruff linting + pip-audit security scan on every push

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Streamlit :8501)                â”‚
â”‚  Query input Â· Answer display Â· Source scores Â· ğŸ‘ğŸ‘ feedbackâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               BACKEND (FastAPI :8000)                        â”‚
â”‚                                                              â”‚
â”‚  POST /ask â”€â”€â–º FeedbackAwareRetriever                        â”‚
â”‚                  1. Embed query (all-MiniLM-L6-v2)           â”‚
â”‚                  2. match_documents RPC (top 2Ã—k)            â”‚
â”‚                  3. UCB1 re-rank (vector + bandit score)      â”‚
â”‚                  4. Build context â†’ Gemini â†’ answer           â”‚
â”‚                                                              â”‚
â”‚  POST /feedback â”€â”€â–º store in Supabase â†’ update bandit        â”‚
â”‚  GET  /health   â”€â”€â–º Supabase connectivity check              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Supabase (pgvector) â”‚   â”‚  Gemini 2.5-flash LLM â”‚
    â”‚  documents table     â”‚   â”‚  (LangChain LCEL)     â”‚
    â”‚  feedback table      â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ upsert (idempotent)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DATA PIPELINE (LangGraph)                       â”‚
â”‚                                                              â”‚
â”‚  fetch_articles â†’ load_articles â†’ translate_non_english      â”‚
â”‚       â”‚                                   â”‚                  â”‚
â”‚  EventRegistry                       Gemini (non-EN)         â”‚
â”‚  8 companies Â· 30 days Â· 50 art/co        â”‚                  â”‚
â”‚                                   chunk_documents            â”‚
â”‚                                  (3200 chars, 400 overlap)   â”‚
â”‚                                          â”‚                   â”‚
â”‚                                  generate_embeddings         â”‚
â”‚                                   (384-dim, batch=64)        â”‚
â”‚                                          â”‚                   â”‚
â”‚                                  index_to_supabase           â”‚
â”‚                                   (upsert on doc_id)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Layer | Technology |
|-------|-----------|
| Backend | FastAPI + Pydantic Settings |
| LLM | Google Gemini 2.5-flash (LangChain LCEL) |
| Embeddings | `sentence-transformers/all-MiniLM-L6-v2` (384d) |
| Vector store | Supabase pgvector |
| Data pipeline | LangGraph (6-node graph) |
| News source | EventRegistry (newsapi.ai) |
| Translation | Gemini + `langdetect` |
| Re-ranking | UCB1 multi-armed bandit |
| Frontend | Streamlit |
| Orchestration | n8n (Docker) |
| CI | GitHub Actions â€” ruff + pip-audit |

---

## Getting Started

### Prerequisites

- Python 3.10+
- A [Supabase](https://supabase.com) project with the `pgvector` extension enabled and a `match_documents` RPC function
- A [Google Gemini](https://aistudio.google.com) API key
- An [EventRegistry](https://newsapi.ai) API key

### Installation

```bash
git clone https://github.com/thesamotar/BI-Assistant.git
cd BI-Assistant
pip install -r requirements.txt
```

### Configuration

```bash
cp .env.example .env
# Fill in SUPABASE_URL, SUPABASE_KEY, GEMINI_API_KEY, EVENT_REGISTRY_API_KEY
```

All available settings are documented in `.env.example`.

### 1. Run the data pipeline

Fetches live articles, translates, chunks, embeds, and indexes to Supabase in one command. Run this first, and re-run periodically to keep data fresh.

```bash
python -m workflows.langgraph_pipeline
```

### 2. Start the backend

```bash
python -m uvicorn backend.main:app --reload --host 127.0.0.1 --port 8000
```

API docs available at `http://localhost:8000/docs`.

### 3. Start the frontend

In a second terminal:

```bash
python -m streamlit run frontend/streamlit_app.py
```

Open `http://localhost:8501`.

### 4. (Optional) n8n orchestrator

```bash
docker-compose up
# http://localhost:5678  â€”  admin / admin123
```

---

## Project Structure

```
BI-Assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI entry point, lifespan, CORS
â”‚   â”œâ”€â”€ config.py                # Pydantic Settings (reads .env)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ request_models.py    # QueryRequest, QueryResponse
â”‚   â”‚   â””â”€â”€ feedback_models.py   # FeedbackRequest, FeedbackType
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ ask.py               # POST /ask
â”‚   â”‚   â”œâ”€â”€ feedback.py          # POST /feedback
â”‚   â”‚   â””â”€â”€ health.py            # GET /health
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ embeddings.py        # HuggingFace embeddings (lru_cache)
â”‚       â”œâ”€â”€ feedback_rl.py       # Supabase client + UCB1 bandit
â”‚       â””â”€â”€ rag_pipeline.py      # FeedbackAwareRetriever + LCEL chain
â”œâ”€â”€ workflows/
â”‚   â””â”€â”€ langgraph_pipeline.py    # 6-node LangGraph ingestion pipeline
â”œâ”€â”€ rl/
â”‚   â”œâ”€â”€ bandit.py                # UCB1Bandit implementation
â”‚   â””â”€â”€ ppo_experiment.py        # PPO re-ranker (research)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ streamlit_app.py         # Streamlit dashboard
â”œâ”€â”€ .github/workflows/ci-cd.yml  # Lint + security CI
â”œâ”€â”€ ruff.toml                    # Ruff lint config
â”œâ”€â”€ .env.example                 # Environment variable template
â”œâ”€â”€ docker-compose.yml           # n8n orchestrator
â””â”€â”€ requirements.txt
```

---

## API Reference

<details>
<summary><code>POST /ask</code></summary>

**Request**
```json
{
  "query": "What are OpenAI's latest product announcements?",
  "top_k": 5
}
```

**Response**
```json
{
  "answer": "OpenAI announced... [https://example.com]",
  "sources": ["https://example.com"],
  "scores": [0.8421],
  "model": "gemini-2.5-flash"
}
```
</details>

<details>
<summary><code>POST /feedback</code></summary>

**Request**
```json
{
  "query": "What are OpenAI's latest product announcements?",
  "answer": "...",
  "sources": ["https://example.com"],
  "feedback": "positive"
}
```
</details>

<details>
<summary><code>GET /health</code></summary>

**Response**
```json
{ "status": "ok", "supabase": "ok" }
```
</details>

---

## How Re-ranking Works

Retrieval is a two-stage process:

1. **Vector search** â€” `match_documents` Supabase RPC retrieves 2Ã— `top_k` candidates by cosine similarity.
2. **UCB1 re-ranking** â€” each candidate URL gets a bandit score:

$$\text{score} = \bar{x} + \sqrt{\frac{2 \ln N}{n}}$$

where $\bar{x}$ is the mean reward (1.0 = ğŸ‘, 0.0 = ğŸ‘), $N$ is total feedback events, and $n$ is feedback count for that URL. Final rank = `vector_score + ucb1_score`.

The bandit state is rebuilt from Supabase on every startup â€” no extra infrastructure needed.

---

## Configuration Reference

| Variable | Default | Description |
|----------|---------|-------------|
| `SUPABASE_URL` | â€” | Supabase project URL |
| `SUPABASE_KEY` | â€” | Service role key |
| `SUPABASE_DB_PASSWORD` | â€” | Database password |
| `GEMINI_API_KEY` | â€” | Google Gemini API key |
| `GEMINI_MODEL` | `gemini-2.5-flash` | Generation model |
| `GEMINI_TRANSLATION_MODEL` | `gemini-2.5-flash` | Translation model |
| `EMBEDDING_MODEL` | `sentence-transformers/all-MiniLM-L6-v2` | Embedding model |
| `EVENT_REGISTRY_API_KEY` | â€” | EventRegistry API key |
| `NEWS_LOOKBACK_DAYS` | `30` | Days of history to fetch |
| `NEWS_MAX_ITEMS_PER_COMPANY` | `50` | Articles per company |
| `DOCUMENTS_TABLE` | `documents` | Supabase table for chunks |
| `FEEDBACK_TABLE` | `feedback` | Supabase table for votes |
| `MATCH_FUNCTION` | `match_documents` | Supabase RPC function |
| `ARTICLES_JSON_PATH` | `genai_competitors_articles.json` | Pipeline output file |
| `FRONTEND_ORIGIN` | `http://localhost:8501` | CORS allowed origin |

---

## CI

Every push and PR to `main` runs two GitHub Actions jobs:

| Job | Tool | Checks |
|-----|------|--------|
| `lint` | `ruff` | Syntax errors, undefined names, bad imports |
| `security` | `pip-audit` | Known CVEs in dependencies |

---

## License

[MIT](LICENSE)
